# Apache Spark
Lecture on Apache Spark for Distributed Systems
## Introduction
This chapter will get you familiar with Apache Spark and how you might use the cluser computing system in in your projects. If you have intrests or projects involving big data, machine learning, and data mining, you might find Spark useful for handling large amounts of data. 
## Definitions 
- Cluster: multiple computers that perform a task as if it were a single computer 
- Open source: a piece of software that is free for users and allows them to freely distribute the software. The source code is also open to users and they may contribute to the development of the software
- Resilient Distributed Datasets (RDD):
- 
## History and Background
## Architecture
## Open Source
## Big Data
## Machine Learning 
## Tutorial 
## Sources
